{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jerry0209/FundamentalLearningEPFL/blob/main/TP9/%5Bexercise%5Dtorch_and_neuralnets_v2_Jerry_Noted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udG5A5Y3-ieU"
      },
      "source": [
        "In this notebook we will approach for the first time PyTorch.\n",
        "First we see how `torch` can help us to avoid long `numpy` code and then we will see how to use `torch` to build a simple neural network for classification.\n",
        "\n",
        "# Part 1: From Numpy to PyTorch\n",
        "\n",
        "**What will you learn in this part**:\n",
        "- Tensors syntax\n",
        "- Autograd\n",
        "- Neural Network modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiQwLN4X-ieW"
      },
      "source": [
        "Let's get back to last week exercise and migrate it to PyTorch. Luckily, the syntax is almost identical. The main difference is that *arrays* are replaced by *tensors*, and all the `np.*` functions become `torch.*`. For more advanced functionalities, we refer you to the [official documentation][torch_doc].\n",
        "\n",
        "[torch_doc]: https://pytorch.org/docs/stable/index.html\n",
        "\n",
        "## Single layer MLP in Numpy\n",
        "\n",
        "Recall the feedforward neural network with a single hidden layer.\n",
        "\n",
        "![simple_mlp](https://github.com/IdePHICS/FundamentalLearningEPFL/blob/main/TP9/simple_mlp.png?raw=1)\n",
        "\n",
        "Below is the Numpy implementation of the activations and the feedforward propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ENj_awlh-ieW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import Tuple\n",
        "from numpy.typing import NDArray\n",
        "\n",
        "def np_sigmoid(t):\n",
        "    \"\"\"apply sigmoid function on t.\"\"\"\n",
        "    return 1.0 / (1 + np.exp(-t))\n",
        "\n",
        "def np_grad_sigmoid(t):\n",
        "    \"\"\"return the derivative of sigmoid on t.\"\"\"\n",
        "    return np_sigmoid(t) * (1 - np_sigmoid(t))\n",
        "\n",
        "def np_mlp( # forward propagation\n",
        "    x: NDArray[np.float64], w_1: NDArray[np.float64], w_2: NDArray[np.float64]\n",
        ") -> Tuple[NDArray[np.float64], NDArray[np.float64], NDArray[np.float64]]:\n",
        "    \"\"\"Feed forward propagation on MLP\n",
        "\n",
        "    Args:\n",
        "        x (NDArray[np.float_]): Input vector of shape (d_in,)\n",
        "        w_1 (NDArray[np.float_]): Parameter matrix of first hidden layer, of shape (d_in, d_hid)\n",
        "        w_2 (NDArray[np.float_]): Parameter vector of output layer, of shape (d_hid,)\n",
        "\n",
        "    Returns:\n",
        "        Tuple[NDArray[np.float], NDArray[np.float], NDArray[np.float]]: Three\n",
        "            arrays `y_hat`, `z_1`, `z_2`, containing repsectively the output and\n",
        "            the two preactivations.\n",
        "    \"\"\"\n",
        "    z_1 = w_1.T @ x # matrix multiplication # input vector of single sample point, e.g. MNIST, each image has 784 entries\n",
        "    # if entire batch, do a different matrix mutiplication\n",
        "    # w_1 is matrix\n",
        "    x_1 = np_sigmoid(z_1)\n",
        "    z_2 = w_2.T @ x_1\n",
        "    # w_2 is vector?\n",
        "    y_hat = np_sigmoid(z_2)\n",
        "\n",
        "    return y_hat, z_1, z_2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pSc6xZC-ieW"
      },
      "source": [
        "And this is the backpropagation with the Mean-squared error loss $\\mathcal L (y, \\hat y) = \\frac{1}{2} \\left( y - \\hat y \\right)^2$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mgWFfK9r-ieW"
      },
      "outputs": [],
      "source": [
        "def np_mlp_backpropagation(\n",
        "    y: NDArray[np.int_],\n",
        "    x: NDArray[np.float64],\n",
        "    w_2: NDArray[np.float64],\n",
        "    y_hat: NDArray[np.float64],\n",
        "    z_1: NDArray[np.float64],\n",
        "    z_2: NDArray[np.float64],\n",
        ") -> Tuple[NDArray[np.float64], NDArray[np.float64]]:\n",
        "    \"\"\"Do backpropagation and get parameter gradients.\n",
        "\n",
        "    Args:\n",
        "        y (NDArray[np.int_]): True label\n",
        "        x (NDArray[np.float64]): Input data\n",
        "        w_2 (NDArray[np.float64]): Readout layer parameters\n",
        "        y_hat (NDArray[np.float64]): MLP output\n",
        "        z_1 (NDArray[np.float64]): Hidden layer preactivations\n",
        "        z_2 (NDArray[np.float64]): Readout layer preactivations\n",
        "\n",
        "    Returns:\n",
        "        Tuple[NDArray[np.float64], NDArray[np.float64]]: Gradients of w_1 and w_2\n",
        "    \"\"\"\n",
        "    # Feed forward\n",
        "    _loss = 0.5 * (y - y_hat)**2\n",
        "\n",
        "    # Backpropogation\n",
        "    # Try to understand this! One of the most important parts\n",
        "    delta_2 = (y_hat - y) * np_grad_sigmoid(z_2)\n",
        "    x_1 = np_sigmoid(z_1)\n",
        "    dw_2 = delta_2 * x_1\n",
        "    delta_1 = delta_2 * w_2* np_grad_sigmoid(z_1)\n",
        "    dw_1 = np.outer(x, delta_1)\n",
        "\n",
        "    return dw_1, dw_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59mqXguL-ieX"
      },
      "source": [
        "Now, we can compute the MLP output and retrieve the gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mJaKlsz-ieX",
        "outputId": "82b4fdf4-dab7-4082-dd60-f8fe8039b1dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 5)\n",
            "(5,)\n"
          ]
        }
      ],
      "source": [
        "x_np = np.array([0.01, 0.02, 0.03, 0.04])\n",
        "w_1_np = np.random.randn(4, 5)\n",
        "w_2_np = np.random.randn(5)\n",
        "\n",
        "y = 1\n",
        "\n",
        "y_hat_np, z_1, z_2 = np_mlp(x_np, w_1_np, w_2_np)\n",
        "dw_1_np, dw_2_np = np_mlp_backpropagation(y, x_np, w_2_np, y_hat_np, z_1, z_2)\n",
        "\n",
        "print(dw_1_np.shape) # gradient shape same as w_1\n",
        "print(dw_2_np.shape) # gradient shape same as w_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paw3R0TG-ieX"
      },
      "source": [
        "This indeed works, but as soon as we change the neural network architecture we have to change our backpropagation function, and keep track of all the computations that involve each parameter. It is a lot of work which we want to delegate to the machine.\n",
        "This is what *automatic differentiation* does, and libraries like PyTorch implement it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_a3Fu93-ieX"
      },
      "source": [
        "## Exercise 1\n",
        "\n",
        "We can manipulate tensors as we want and, by asking for `require_grad=True`, PyTorch handles automatic differentation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kySF0coz-ieX"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1OAuz5v-ieX",
        "outputId": "bfa5c672-7493-4812-c526-61195f08eede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c tensor(nan, grad_fn=<SumBackward0>)\n",
            "c.shape: torch.Size([])\n",
            "b.grad: tensor([ 0.9469,  4.7133, -4.1079,  8.7139, -0.2661])\n",
            "b.grad.shape: torch.Size([5])\n"
          ]
        }
      ],
      "source": [
        "# EXAMPLE\n",
        "\n",
        "# Tensor can track gradient\n",
        "# 'True', each tensor keep its gradient\n",
        "# We only use Torch array and Torch tensor\n",
        "\n",
        "a = torch.randn(10, 5) # 10 row, 5 column\n",
        "b = torch.ones(5, requires_grad=True)\n",
        "\n",
        "# Note that c is a scalar\n",
        "c = torch.log(a @ b).sum() # Forward\n",
        "print(\"c\", c)\n",
        "print(\"c.shape:\", c.shape)\n",
        "\n",
        "# We ask to perform backpropagation #!!\n",
        "c.backward() # c looks into its gradients to do the backward\n",
        "\n",
        "print(\"b.grad:\", b.grad)\n",
        "print(\"b.grad.shape:\", b.grad.shape) # 5, since tensor has 5 entries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX6MccXS-ieX"
      },
      "source": [
        "We now convert the previous code to PyTorch. Autograd is responsible of keeping track of each element in the computations, so we only need to implement the forward pass!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V7MhwQGw-ieX"
      },
      "outputs": [],
      "source": [
        "def sigmoid(t) -> torch.FloatTensor:\n",
        "    \"\"\"apply sigmoid function on t.\"\"\"\n",
        "    # Look at Pytorch document\n",
        "    #vvvvv YOUR CODE HERE vvvvv#˙\n",
        "    return 1.0/(1 + torch.exp(-t))\n",
        "\n",
        "    #^^^^^^^^^^^^^^^^^^^^^^^^^^#\n",
        "\n",
        "def mlp(\n",
        "    x: torch.Tensor, w_1: torch.Tensor, w_2: torch.Tensor\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Feed forward propagation on MLP\n",
        "\n",
        "    Args:\n",
        "        x (torch.Tensor): Input vector of shape (d_in,)\n",
        "        w_1 (torch.Tensor): Parameter matrix of first hidden layer, of shape (d_in, d_hid) !!\n",
        "        w_2 (torch.Tensor): Parameter vector of output layer, of shape (d_hid,) !!\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Network output\n",
        "    \"\"\"\n",
        "    #vvvvv YOUR CODE HERE vvvvv# !! Different from before\n",
        "\n",
        "    z_1 = w_1.T @ x\n",
        "    x_1 = sigmoid(z_1)\n",
        "    z_2 = w_2.T @ x_1\n",
        "    y_hat = sigmoid(z_2)\n",
        "\n",
        "    #^^^^^^^^^^^^^^^^^^^^^^^^^^#\n",
        "\n",
        "    return y_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Tuq731G-ieY"
      },
      "source": [
        "Now, we can verify that the output corresponds to the numpy implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSULL6FK-ieY",
        "outputId": "674de1ed-2cf7-47a0-e152-d5f09368f933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4175153287.py:26: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4421.)\n",
            "  z_2 = w_2.T @ x_1\n"
          ]
        }
      ],
      "source": [
        "# Compare manual result and Pytorch Result\n",
        "# Inputs are tensor, so you have to convert np array to tensors\n",
        "#vvvvv YOUR CODE HERE vvvvv#\n",
        "\n",
        "# Convert arrays to tensors. Mind that we will ask for parameters gradients!\n",
        "x = torch.tensor(x_np)\n",
        "w_1 = torch.tensor(w_1_np, requires_grad=True)\n",
        "w_2 = torch.tensor(w_2_np, requires_grad=True)\n",
        "\n",
        "y_hat = mlp(x, w_1, w_2) # Foward\n",
        "\n",
        "#^^^^^^^^^^^^^^^^^^^^^^^^^^#\n",
        "loss = 0.5 * (y - y_hat)**2 # Loss\n",
        "#Now perform backpropagation\n",
        "loss.backward() # Back propagation\n",
        "#^^^^^^^^^^^^^^^^^^^^^^^^^^#\n",
        "\n",
        "print(np.allclose(w_1.grad.numpy(), dw_1_np)) # convert into numpy to compare\n",
        "print(np.allclose(w_2.grad.numpy(), dw_2_np))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGJqPngH-ieY"
      },
      "source": [
        "## Exercise 2.1\n",
        "\n",
        "Computing gradients has now got much easier! :grin:\n",
        "\n",
        "Still, PyTorch provides an even easier interface to build and train neural networks, whose components are in the `torch.nn` module.\n",
        "The main tool is the `torch.nn.Module` class, from which all neural networks shall inherit. This must implement a `forward` method, and, if needed, declare its parameters in the `__init__` method.\n",
        "\n",
        "Let's convert our MLP to a proper Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xOe4u7Jm-ieY"
      },
      "outputs": [],
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, dim_in: int, dim_hidden: int) -> None: # Object oriented programming\n",
        "        #vvvvv YOUR CODE HERE vvvvv# !! TA's\n",
        "        super().__init__()\n",
        "        self.w_1 = torch.nn.Parameter( # define the matrix\n",
        "            torch.randn(dim_in, dim_hidden, requires_grad=True)\n",
        "        )\n",
        "        self.w_2 = torch.nn.Parameter(\n",
        "            torch.randn((dim_hidden, 1), requires_grad=True)\n",
        "        )\n",
        "\n",
        "\n",
        "        #^^^^^^^^^^^^^^^^^^^^^^^^^^#\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        #vvvvv YOUR CODE HERE vvvvv#\n",
        "\n",
        "        z_1 = self.w_1.T @ x\n",
        "        x_1 = z_1.sigmoid()\n",
        "        z_2 = self.w_2.T @ x_1\n",
        "\n",
        "        return z_2.sigmoid()\n",
        "\n",
        "        #^^^^^^^^^^^^^^^^^^^^^^^^^^#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tdnUjIo-ieY"
      },
      "source": [
        "Even better, `torch.nn` comes with a lot of layers and functions which are ready to use.\n",
        "\n",
        "For instance, we have a `torch.sigmoid` function, as well as `torch.nn.Linear` layer and a `torch.nn.MSELoss` loss.\n",
        "\n",
        "Here is a minimal implementation of our forward and backward pass:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AziwUva6-ieY"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class MyMLP(nn.Module):\n",
        "    def __init__(self, dim_in: int, dim_hidden: int) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # NOTE: Linear has a `bias` term by default!\n",
        "        self.linear1 = nn.Linear(dim_in, dim_hidden, bias=False)\n",
        "        self.linear2 = nn.Linear(dim_hidden, 1, bias=False)\n",
        "\n",
        "    def forward(self, x): ## 一层一层迭代计算\n",
        "        x = self.linear1(x).sigmoid()\n",
        "        return self.linear2(x).sigmoid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_821zKvg-ieY"
      },
      "source": [
        "Now initialize your model and compute the gradients with respect to the MSE loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8gTbaXR-ieY",
        "outputId": "74214b25-324f-41af-93e7-95623f572c31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyMLP(\n",
            "  (linear1): Linear(in_features=5, out_features=10, bias=False)\n",
            "  (linear2): Linear(in_features=10, out_features=1, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "DIM_IN = 5\n",
        "DIM_HIDDEN = 10\n",
        "\n",
        "x = torch.ones(DIM_IN)\n",
        "y = torch.tensor([0.1])\n",
        "\n",
        "#vvvvv YOUR CODE HERE vvvvv#\n",
        "\n",
        "my_mlp = MyMLP(DIM_IN, DIM_HIDDEN)\n",
        "print(my_mlp)\n",
        "## my_mlp is the output??\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "loss(y, my_mlp(x)).backward()\n",
        "\n",
        "\n",
        "#^^^^^^^^^^^^^^^^^^^^^^^^^^#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BHksX6A-ieY"
      },
      "source": [
        "## Exercise 2.2\n",
        "\n",
        "\n",
        "Check the sizes of the gradients of each layer and verify that they correspond to what you expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC2uSsto-ieY",
        "outputId": "f5f5b2c8-9c30-4189-c5a2-25951aaeabd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 5])\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "#vvvvv YOUR CODE HERE vvvvv#\n",
        "\n",
        "# Note that we have multiple ways to retrieve the parameters\n",
        "gw_1 = my_mlp.linear1.get_parameter('weight')\n",
        "gw_2 = my_mlp.linear2.get_parameter('weight')\n",
        "print(gw_1.shape)\n",
        "print(gw_2.shape)\n",
        "\n",
        "#^^^^^^^^^^^^^^^^^^^^^^^^^^#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRDjrh-q-ieY"
      },
      "source": [
        "## One more thing..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA94J8P6-ieY"
      },
      "source": [
        "The `nn.Sequential` module stacks the given layer one after the other.\n",
        "Still, to get more control on the forward, it is better to stick to self-defined module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKo07yYF-ieY",
        "outputId": "e898fd26-a6db-4225-dce6-5f0b676c0a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=5, out_features=10, bias=False)\n",
            "  (1): Sigmoid()\n",
            "  (2): Linear(in_features=10, out_features=1, bias=False)\n",
            "  (3): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "sequential_mlp = nn.Sequential( # Create Block\n",
        "    nn.Linear(DIM_IN, DIM_HIDDEN, bias=False),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(DIM_HIDDEN, 1, bias=False),\n",
        "    nn.Sigmoid(),\n",
        ")\n",
        "\n",
        "print(sequential_mlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqteS28_-ieY"
      },
      "source": [
        "# Part 2: Hands on MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3ZHqSKq-ieY"
      },
      "source": [
        "**What you will learn in the second part**: This lab serves as an introduction to PyTorch. We will learn the different steps required in training a deep learning model with modern libraries, such as PyTorch.\n",
        "\n",
        "So, which are these steps?\n",
        "\n",
        "* Preliminaries:\n",
        "    * load the train and test datasets, `train_dataset` and `test_dataset` (MNIST in our case)\n",
        "    * turn the datasets into a \"dataloaders\": `train_dataloader` and `test_dataloader`\n",
        "    * define your `model` architecture\n",
        "    * define your `optimizer`, e.g. SGD\n",
        "\n",
        "\n",
        "* Training: Now we have all the building blocks and we need to make our model \"learn\". In most cases, the training follows a specific \"recipe\". Specifically, we feed the `model` the whole `train_dataset` using batches that come from the `train_dataloader`. We repeat this a certain number of times, called `epochs`. Each epoch consists of `batches`. So what do we do for each batch?\n",
        "    * zero out the optimizer. In essence we prepare the optimizer for the incoming data\n",
        "    * compute the output of the model $f(\\cdot)$ for our current data: $x\\mapsto f(x)$\n",
        "    * compute the loss: $\\mathcal{L}(f(x), y)$ where $y$ denotes the ground truth\n",
        "    * perform the `backpropagation` algorithm which involves computing the gradients and performing the update rule\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTqWQ1Ab-ieY"
      },
      "source": [
        "## Getting the preliminaries out of the way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dospWAwF-ieY"
      },
      "outputs": [],
      "source": [
        "# first we load all the necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader ## Crucial Components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tniBDH2d-ieY"
      },
      "source": [
        "We now load the datasets. We are going to work with MNIST and our goal is classify digits. This is a popular dataset and PyTorch offers it out-of-the-box, making our life easy! We simply need to call the corresponding method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pE9ETfT-ieY",
        "outputId": "e24c9ad8-18aa-44a7-ecad-00e6d4a46e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 57.2MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.70MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.5MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.93MB/s]\n"
          ]
        }
      ],
      "source": [
        "# The data are given as PIL images. We need to convert our data to a type\n",
        "# that is readable by a Neural Network. Thus, we use the ToTensor() \"transform\"\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    # T.Normalize((0.1307,), (0.3081,)) ## In practice, we may want to stack differnt (steps)? We need normalization\n",
        "])\n",
        "\n",
        "# load the train dataset\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data/',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform)\n",
        "\n",
        "# load the test dataset\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data/',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ed05Bbq-ieY",
        "outputId": "7a5cffaf-64af-4d65-f009-0f085f203690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# define the hyperparameters\n",
        "BATCH_SIZE = 1024\n",
        "TEST_BATCH_SIZE = 2048\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "# find out which device is available\n",
        "def device_type():\n",
        "    if torch.cuda.is_available(): # GPU\n",
        "        return 'cuda'\n",
        "    elif torch.backends.mps.is_available(): # GPU, Apple Silicon\n",
        "        return 'mps'\n",
        "    else:\n",
        "        return 'cpu'\n",
        "DEVICE = torch.device(device_type())\n",
        "print(DEVICE)\n",
        "\n",
        "# Change runtime type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shCo9hTp-ieY"
      },
      "source": [
        "However, we cannot use the whole dataset; it is too large for computers to handle. Instead, we perform *stochastic* gradient descent, i.e. we feed the model part of the data called batches. In order to do so, we use Pytorch DataLoaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "c5zewC2_-ieY"
      },
      "outputs": [],
      "source": [
        "# Construct the dataloader for the training dataset.\n",
        "# Here we shuffle the data to promote stochasticity.\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset, # which dataset to use\n",
        "    batch_size=BATCH_SIZE, # in one gradient computation\n",
        "    shuffle=True, ## ? not so important, when do computation again, maybe you don't want the same batches and same order?\n",
        "    num_workers=2)\n",
        "\n",
        "\n",
        "# Construct the dataloader for the testing dataset.\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=TEST_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "319wGSoK-ieY"
      },
      "source": [
        "Now, let's visualize some samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "aKLRrO5g-ieZ",
        "outputId": "2ef3a254-d325-4d4c-9483-87cf3256e4d1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get the first 10 images of the train dataset.\n",
        "images = next(iter(train_dataloader))[0][:10]\n",
        "grid = torchvision.utils.make_grid(images, nrow=5, padding=10)\n",
        "\n",
        "def show(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "\n",
        "show(grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NFxTgQ2-ieZ"
      },
      "source": [
        "## Exercise 3\n",
        "Now, we are ready to define our model. We will start with a simple model, a MultiLayer Perceptron (MLP) with 2 layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Hxt7VlLq-ieZ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        # define the different modules of the network\n",
        "        super().__init__()\n",
        "        # How many features should our model have?\n",
        "        self.fc1 = nn.Linear(784, 50) # input 784, hidden 50\n",
        "\n",
        "        # How many outputs should our model have?\n",
        "        self.fc2 = nn.Linear(50, 10) # 10 outputs, 0 - 9\n",
        "        # we also define the non-linearity\n",
        "        self.relu = nn.ReLU() # ? why\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor: ## how to do this?\n",
        "        # ***************************************************\n",
        "        # INSERT YOUR CODE HERE\n",
        "        # You should (a) transform the input to a size that is readable\n",
        "        # by the MLP and (b) pass the input x successively\n",
        "        # through the layers.\n",
        "        # ***************************************************\n",
        "        # transform the image to a vector\n",
        "\n",
        "        # view is very important\n",
        "        # create tensor but do not cost memory, do not create a copy of the tensor, used to reshape the tensor\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        x = x.view(batch_size, -1)\n",
        "        # pass the vectored image through the layers\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XNKfLXSj-iec"
      },
      "outputs": [],
      "source": [
        "# initialize the model\n",
        "model = Net() # defined in previous\n",
        "\n",
        "# move model to device\n",
        "model = model.to(DEVICE) #  Maybe put into GPU\n",
        "\n",
        "# define the optimizer in order to train the model\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SLpH5eP-iec"
      },
      "source": [
        "We now define:\n",
        "* the `fit` function that performs the training part\n",
        "* the `predict` function that takes as input the test dataloader and prints the performance metrics (e.g. accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UPasqx8j-iec"
      },
      "outputs": [],
      "source": [
        "def train_epoch( # 1 epoch -> go through all the dataset\n",
        "    model: nn.Module,\n",
        "    train_dataloader: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    device: torch.device\n",
        "    ):\n",
        "    '''\n",
        "    This function implements the core components of any Neural Network training regiment.\n",
        "    In our stochastic setting our code follows a very specific \"path\". First, we load a single batch and zero the optimizer.\n",
        "    Then we perform the forward pass, compute the gradients and perform the backward pass. And ...repeat!\n",
        "    '''\n",
        "\n",
        "    running_loss = 0.0\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
        "        # move data and target to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad() # clear gradients from previous step\n",
        "\n",
        "        # do the forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # compute the loss\n",
        "        loss = F.cross_entropy(output, target) # same as logistic for binary, generalization to more parameters\n",
        "\n",
        "        # compute the gradients\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        # perform the gradient step\n",
        "        optimizer.step() # SGD\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item() # convert tensor number to py number\n",
        "\n",
        "    return running_loss / len(train_dataloader.dataset) # mean loss in the batch\n",
        "\n",
        "\n",
        "def fit(\n",
        "    model: nn.Module,\n",
        "    train_dataloader: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epochs: int,\n",
        "    device: torch.device):\n",
        "    '''\n",
        "    the fit method simply calls the train_epoch() method for a\n",
        "    specified number of epochs.\n",
        "    '''\n",
        "\n",
        "    # keep track of the losses in order to visualize them later\n",
        "    # Train for numerous epochs:\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = train_epoch(\n",
        "            model=model,\n",
        "            train_dataloader=train_dataloader,\n",
        "            optimizer=optimizer,\n",
        "            device=device\n",
        "        )\n",
        "        print(f\"Epoch {epoch}: Loss={running_loss}\")\n",
        "        losses.append(running_loss)\n",
        "\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XbidaUeK-iec"
      },
      "outputs": [],
      "source": [
        "def predict(model: nn.Module, test_dataloader: DataLoader, device: torch.device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad(): # no training! don't change gradient at test data\n",
        "        for data, target in test_dataloader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data) # compute the output\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            test_loss += loss.item()\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "\n",
        "    test_loss /= len(test_dataloader.dataset)\n",
        "    accuracy = 100. * correct / len(test_dataloader.dataset) # percentage of the correct prediction\n",
        "\n",
        "    print(f'Test set: Avg. loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_dataloader.dataset)} ({accuracy:.0f}%)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw2HHD8Z-iec"
      },
      "source": [
        "We perform a \"sanity check\". Our model is at the moment initialized randomly and we have 10 classes (each class has approximately the same number of samples). This means that we should get random performance -> ~10% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caXBof_k-iec",
        "outputId": "2f693370-4f7d-42ef-c86b-0a3d57cc6c66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Avg. loss: 0.0012, Accuracy: 595/10000 (6%)\n"
          ]
        }
      ],
      "source": [
        "predict(model=model, test_dataloader=test_dataloader, device=DEVICE) # if not trained, model output should give you similar number of samples in each category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xtY9gRh-iec",
        "outputId": "ed186f90-fd47-4715-f984-9b999c70122f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss=0.0022322166045506795\n",
            "Epoch 1: Loss=0.0021271461844444275\n",
            "Epoch 2: Loss=0.001994601875543594\n",
            "Epoch 3: Loss=0.0018370180368423462\n",
            "Epoch 4: Loss=0.001663448824485143\n",
            "Epoch 5: Loss=0.0014836223145325979\n",
            "Epoch 6: Loss=0.0013145763417085011\n",
            "Epoch 7: Loss=0.0011663947840531666\n",
            "Epoch 8: Loss=0.0010425046185652414\n",
            "Epoch 9: Loss=0.0009419233739376068\n",
            "Epoch 10: Loss=0.0008601792027552922\n",
            "Epoch 11: Loss=0.0007939862112204234\n",
            "Epoch 12: Loss=0.0007400357335805893\n",
            "Epoch 13: Loss=0.0006953178922335306\n",
            "Epoch 14: Loss=0.0006582826286554336\n",
            "Epoch 15: Loss=0.0006265652547279994\n",
            "Epoch 16: Loss=0.000599563271800677\n",
            "Epoch 17: Loss=0.000576259109377861\n",
            "Epoch 18: Loss=0.0005559835841258367\n",
            "Epoch 19: Loss=0.0005377425154050191\n"
          ]
        }
      ],
      "source": [
        "# train for 20 epochs\n",
        "losses = fit(\n",
        "    model=model,\n",
        "    train_dataloader=train_dataloader,\n",
        "    optimizer=optimizer,\n",
        "    epochs=20,\n",
        "    device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtMm8k5K-iec"
      },
      "source": [
        "Let's visualize the loss progression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvJlwEaC-iec"
      },
      "outputs": [],
      "source": [
        "plt.plot(losses)\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss progression across epochs\") # it should decrease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3S89PzaP-iec"
      },
      "outputs": [],
      "source": [
        "predict(model=model, test_dataloader=test_dataloader, device=DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd2uO8St-iec"
      },
      "source": [
        "The results are not very good. There are some major problems. We see from the plot above that the loss keeps dropping and does not \"plateau\". This indicates that we can run the optimization a few more epochs and improve the performance. Another point is that our learning rate is too slow or the selection of vanilla SGD as our optimizer is not optimal. In the next section we will see that simply changing the optimizer (from SGD to Adam) yields very different results!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfVEDqG6-iec"
      },
      "source": [
        "## Exercise 4: CNN\n",
        "\n",
        "## Evaluated Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aRo71c_-iec"
      },
      "source": [
        "Notice that the MLP does not take into account the nature of images: close pixels convey local information that is important. Using an MLP, we do not have the notion of the \"pixel neighbourhood\". Therefore, we neglect important information with an MLP. However, there are models better suited for vision problems, such as Convolutional Neural Networks or CNNs.\n",
        "\n",
        "With the code structure we have created, we can simply define a CNN and test its performance quickly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVsNJ0Ea-iec"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # ************ YOUR CODE HERE ************\n",
        "        # define a CNN with 2 convolutional layers, followed by ReLU and Maxpool each,\n",
        "        # and a fully connected layer at the end.\n",
        "        # Hint: you could use nn.Sequential() for the convolutional part\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ************ YOUR CODE HERE ************\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akg-rnd1-iec"
      },
      "outputs": [],
      "source": [
        "# initialize model\n",
        "cnn = CNN().to(DEVICE)\n",
        "\n",
        "# define the optimizer. Use Adam\n",
        "optimizer = optim.Adam(cnn.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# train the CNN\n",
        "losses = fit(\n",
        "    model=cnn,\n",
        "    train_dataloader=train_dataloader,\n",
        "    optimizer=optimizer,\n",
        "    epochs=15,\n",
        "    device=DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4qDdQXq-iec"
      },
      "outputs": [],
      "source": [
        "# How does the CNN perform compared to the MLP?\n",
        "predict(model=cnn, test_dataloader=test_dataloader, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGHUSFyf-iec"
      },
      "outputs": [],
      "source": [
        "plt.plot(losses)\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.yscale('log')\n",
        "plt.title(\"Loss progression across epochs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbdbfz_I-iec"
      },
      "source": [
        "# Part 3: To go further: play with CIFAR10\n",
        "\n",
        "MNIST is a fairly simple dataset. What happens in more challenging datasets? Try to train a network on CIFAR10 dataset and see how it performs. You can use the same code as above, but you need to change the model architecture."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "foli25",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}