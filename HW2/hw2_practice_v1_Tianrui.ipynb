{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Jerry0209/FundamentalLearningEPFL/blob/main/HW2/hw2_practice_v1_Tianrui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCUdY3FqwMEh"
   },
   "source": [
    "# Homework 2: mask detection for the next pandemic\n",
    "You heard rumors from biology department of EPFL about a new version of a corona virus spreading out next year, already called COVID-25. The virus is so dangerous that you are asked to develop a mask detection system to be deployed in all public places. The system should be able to detect if a person is wearing a mask or not. You are given a dataset of images of people with and without masks. Your task is to develop a machine learning model that can detect if a person is wearing a mask or not.\n",
    "\n",
    "**IMPORTANT NOTE:** The evaluation of this homework will be done on an hidden dataset. It is important that your notebook runs without errors, otherwise we will not be able to evaluate some questions, resulting in a grade 0 for that part. Make sure to double check your code before submitting the notebook. We provide a simple `evaluate` function that you can use to make sure that all the necessary functions are implemented correctly; the function will warn you if it detects that a good prediction cannot be made. `evaluate` takes just one argument: the `scikit-learn` model that you have trained. It expects the model to have a `predict` method that works on a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2ekAr4B6wMEj"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/test.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluate\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\FundamentalLearningEPFL\\HW2\\evaluation.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m         y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n\u001b[1;32m---> 11\u001b[0m X, y \u001b[38;5;241m=\u001b[39m load_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate\u001b[39m(model: BaseEstimator):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# check if model is an instance of BaseEstimator\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\FundamentalLearningEPFL\\HW2\\evaluation.py:6\u001b[0m, in \u001b[0;36mload_file\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_file\u001b[39m(file):\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mfile\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[0;32m      7\u001b[0m         X \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m         y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:459\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    457\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mfspath(file), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    460\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/test.npz'"
     ]
    }
   ],
   "source": [
    "from evaluation import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjgCsFrYwMEk"
   },
   "source": [
    "## Data loading and preprocessing\n",
    "The dataset consists in $n$ images of dimension 128x128 pixels. Each pixel is represented by 3 values (RGB). The dataset is divided in two classes: 0 for people with the mask and 1 for people without the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seoGk-IqwMEk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "def load_file(file):\n",
    "    with np.load('data/'+file+'.npz') as data:\n",
    "        X = data['X']\n",
    "        y = data['y']\n",
    "    return X, y\n",
    "\n",
    "X, y = load_file('train')\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4POAg0HwMEk"
   },
   "source": [
    "**Question 1.** Plot few images, and check the distribution of the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtOGknEGwMEk"
   },
   "source": [
    "**Question 2.** Reshape each image in the dataset to a flat vector. Split the dataset into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9D3fWQE8wMEl"
   },
   "source": [
    "## Logistic regression\n",
    "\n",
    "**Question 3.** Train a logistic regression model on the training data, comparing the accuracies of $\\ell_1$ and $\\ell_2$ penalties. What is the train and test accuracy of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGAxqNG5wMEl"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluate(model)\n",
    "# Make sure the line above runs without errors before submitting your solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQMVQw1HwMEl"
   },
   "source": [
    "**Question 4.** Make a more extensive search of possible Logistic Regressors. Crossvalidate the following parameters:\n",
    "- penalty: `['l1', 'l2']`\n",
    "- $C$: range from $10^{-3}$ to $10^3$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgBsGoivwMEl"
   },
   "outputs": [],
   "source": [
    "# Official evaluation!\n",
    "evaluate(logistic_model)\n",
    "# Make sure the line above runs without errors before submitting your solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qN6bieSywMEl"
   },
   "source": [
    "## SVM\n",
    "**Question 4.** Train a linear SVM model on the training data and crossvalidate the parameter $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8Mz83RlwMEl"
   },
   "outputs": [],
   "source": [
    "# Official evaluation!\n",
    "evaluate(svm_model)\n",
    "# Make sure the line above runs without errors before submitting your solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2vqPQfcwMEl"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ya1muKsKwMEl"
   },
   "source": [
    "**Question 5.** Train a Random Forest model on the training data and crossvalidate the parameters:\n",
    "- `n_estimators`\n",
    "- `max_depth`\n",
    "- `criteria`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0fzYUqNwMEm"
   },
   "outputs": [],
   "source": [
    "# Official evaluation!\n",
    "evaluate(rf_model)\n",
    "# Make sure the line above runs without errors before submitting your solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-OeIv6GwMEm"
   },
   "source": [
    "## Extra data\n",
    "Digging in his archive, EPFL Health autorities found a another dataset of images with the same format. This dataset is called `extratrain`. Use this dataset to improve the performance of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYlng4miwMEm"
   },
   "outputs": [],
   "source": [
    "X_extra, y_extra = load_file('extra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hsh08P2cwMEm"
   },
   "source": [
    "**Question 6.** Is this new dataset good? What problem does it have compared to the original dataset, if any?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJccd9LzwMEm"
   },
   "source": [
    "**Question 7.** Evaluate the performance of the cross-validated models you found in the previous questions on the new dataset. Is the performance better or worse? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebzS4CyOwMEm"
   },
   "source": [
    "**Question 8.** Train the most promising model using the new dataset, and crossvalidate. Is the performance better or worse? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIW4PxnmwMEm"
   },
   "outputs": [],
   "source": [
    "# Official evaluation!\n",
    "evaluate(newrf_model)\n",
    "# Make sure the line above runs without errors before submitting your solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Un1-YLLkwMEm"
   },
   "source": [
    "**Question 9:** Join the `train` and `extra` datasets and repeat the previous point. What is the best model and its accuracy on the combined dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FepH3bqPwMEm"
   },
   "outputs": [],
   "source": [
    "# Official evaluation!\n",
    "evaluate(grid.best_estimator_)\n",
    "# Make sure the line above runs without errors before submitting your solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iUlfem5wMEm"
   },
   "source": [
    "**Question 10:** Resample the joined dataset to solve the joined dataset \"problem\". Train a Random Forest with crossvalidation and discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gc6FABGFwMEm"
   },
   "outputs": [],
   "source": [
    "# Official evaluation!\n",
    "evaluate(oversampled_rf_model)\n",
    "# Make sure the line above runs without errors before submitting your solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8C448OmwMEn"
   },
   "source": [
    "**Question 11:** Repeat the previous question, but this time use `LogisticRegression` as the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erO5QCF8wMEn"
   },
   "source": [
    "**Question 12:** Train the best model you can given the data available. Describe your technique and justify your choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bv7L3XtmwMEn"
   },
   "source": [
    "**Question Bonus:** You have been told that is much more important to detect people without masks than people with masks. How would you change your model to take this into account?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
