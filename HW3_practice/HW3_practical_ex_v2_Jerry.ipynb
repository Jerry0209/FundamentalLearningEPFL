{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: optimization of a CNN model\n",
    "The task of this homework is to optimize a CNN model for the CIFAR-100. You are free to define the architecture of the model, and the training procedure. The only contraints are:\n",
    "- It must be a `torch.nn.Module` object\n",
    "- The number of trained parameters must be less than 1 million\n",
    "- The test dataset must not be used for any step of training.\n",
    "- The final training notebook should run on Google Colab within a maximum 1 hour approximately.\n",
    "- Do not modify the random seed, as they are needed for reproducibility purpose.\n",
    "\n",
    "For the grading, you must use the `evaluate` function defined below. It takes a model as input, and returns the test accuracy as output.\n",
    "\n",
    "As a guideline, you are expected to **discuss** and motivate your choices regarding:\n",
    "- Model architecture\n",
    "- Hyperparameters (learning rate, batch size, etc)\n",
    "- Regularization methods\n",
    "- Optimizer\n",
    "- Validation scheme\n",
    "\n",
    "A code without any explanation of the choices will not be accepted. Test accuracy is not the only measure of success for this homework.\n",
    "\n",
    "Remember that most of the train process is randomized, store your model's weights after training and load it before the evaluation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Preventing potential library conflicts on my Windows machine---#\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Fix all random seeds\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# For full determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Import the best device available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# load the data\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "def evaluate(model):\n",
    "    params_count = sum(p.numel() for p in model.parameters())\n",
    "    print('The model has {} parameters'.format(params_count))\n",
    "\n",
    "    if params_count > int(1e6):\n",
    "        print('The model has too many parameters! Not allowed to evaluate.')\n",
    "        return\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "    # print in bold red in a notebook\n",
    "    print('\\033[1m\\033[91mAccuracy on the test set: {}%\\033[0m'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of a simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  556708\n"
     ]
    }
   ],
   "source": [
    "class TinyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = torch.nn.Linear(8*8*64, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.conv1(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = torch.nn.functional.relu(self.conv2(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 8*8*64)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "print(\"Model parameters: \", sum(p.numel() for p in TinyNet().parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of basic training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4.6139\n",
      "Epoch [2/10], Loss: 4.5809\n",
      "Epoch [3/10], Loss: 4.5755\n",
      "Epoch [4/10], Loss: 4.5898\n",
      "Epoch [5/10], Loss: 4.5963\n",
      "Epoch [6/10], Loss: 4.5981\n",
      "Epoch [7/10], Loss: 4.6149\n",
      "Epoch [8/10], Loss: 4.5327\n",
      "Epoch [9/10], Loss: 4.5011\n",
      "Epoch [10/10], Loss: 4.3966\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = TinyNet()\n",
    "model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 556708 parameters\n",
      "\u001b[1m\u001b[91mAccuracy on the test set: 3.4%\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# save the model on a file\n",
    "torch.save(model.state_dict(), 'tiny_net.pt')\n",
    "\n",
    "loaded_model = TinyNet()\n",
    "loaded_model.load_state_dict(torch.load('tiny_net.pt', weights_only=True))\n",
    "evaluate(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My TinyResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions needed, copy from training_utils.py of course material TP10\n",
    "# import everything else that we need\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function implements the core components of any Neural Network training regiment.\n",
    "    In our stochastic setting our code follows a very specific \"path\". First, we load the batch\n",
    "    a single batch and zero the optimizer. Then we perform the forward pass, compute the gradients and perform the backward pass. And ...repeat!\n",
    "    \"\"\"\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        # move data and target to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # do the forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        # compute the loss\n",
    "        # loss = F.cross_entropy(output, target)\n",
    "        loss = F.cross_entropy(output, target, label_smoothing=0.1)\n",
    "\n",
    "        # compute the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # perform the gradient step\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(train_dataloader)\n",
    "\n",
    "\n",
    "def fit(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    "):\n",
    "    \"\"\"\n",
    "    the fit method simply calls the train_epoch() method for a\n",
    "    specified number of epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    # keep track of the losses in order to visualize them later\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = train_epoch(\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "        )\n",
    "        print(f\"Epoch {epoch}: Loss={running_loss}\")\n",
    "        losses.append(running_loss)\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "def predict(\n",
    "    model: nn.Module, test_dataloader: DataLoader, device: torch.device, verbose=True\n",
    "):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, target, reduction=\"sum\")\n",
    "            test_loss += loss.item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    accuracy = 100.0 * correct / len(test_dataloader.dataset)\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Test set: Avg. loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_dataloader.dataset)} ({accuracy:.0f}%)\"\n",
    "        )\n",
    "\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "def visualize_images(dataloader):\n",
    "    images = next(iter(dataloader))[0][:10]\n",
    "    grid = torchvision.utils.make_grid(images, nrow=5, padding=10)\n",
    "\n",
    "    def show(img):\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation=\"nearest\")\n",
    "\n",
    "    show(grid)\n",
    "\n",
    "\n",
    "def plot_loss(losses, ylim=None):\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.ylim(ylim)\n",
    "    plt.title(\"Loss progression across epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# define the hyperparameters\n",
    "BATCH_SIZE = 1024\n",
    "TEST_BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# find out which device is available\n",
    "DEVICE = None\n",
    "if torch.cuda.is_available():\n",
    "    # Requires NVIDIA GPU with CUDA installed\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    # Requires Apple computer with M1 or later chip\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    # Not recommended, because it's slow. Move to Google Colab!\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation has been applied to train_dataset.transform\n"
     ]
    }
   ],
   "source": [
    "# First we load all the necessary libraries\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Data Argumentation\n",
    "# CIFAR-10 Mean and Std\n",
    "# These values are commonly used for CIFAR-10 normalization\n",
    "stats = ((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "\n",
    "\n",
    "# 1. Define transformations for data augmentation (applied only to the training set)\n",
    "# Includes: random cropping, random horizontal flipping, conversion to Tensor, and normalization\n",
    "train_transform_augmented = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),       # Randomly crop the image after padding it with 4 pixels on all sides\n",
    "    transforms.RandomHorizontalFlip(),          # Horizontally flip the image with a 50% probability\n",
    "    transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.CIFAR10), # AutoAugment\n",
    "    transforms.ToTensor(),                      # Mandatory step: convert the image to a PyTorch Tensor\n",
    "    # Normalize using the standard mean and standard deviation for the CIFAR-10 dataset\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 2. Define transformations for the test set (typically no augmentation, but normalization is advised to match the training data)\n",
    "test_transform_normalized = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 3. [Crucial Step] Directly overwrite the 'transform' attribute of the original dataset object\n",
    "# This ensures that the train_dataloader automatically applies the new augmentation strategy when fetching data\n",
    "train_dataset.transform = train_transform_augmented\n",
    "test_dataset.transform = test_transform_normalized\n",
    "\n",
    "print(\"Data augmentation has been applied to train_dataset.transform\")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2)\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit function with scheduler (Reference from TP10)\n",
    "def fit_scheduler(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    "    scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None # Scheduler\n",
    "):\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = train_epoch(\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "        )\n",
    "        print(f\"Epoch {epoch}: Loss={running_loss}\")\n",
    "        losses.append(running_loss)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step() \n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny ResNet Model (Reference from TP10)\n",
    "\n",
    "class TinyResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=100): # CHANGE: Default classes to 100\n",
    "        super().__init__()\n",
    "        # CHANGE: Reduce initial channels from 64 to 32 to save parameters\n",
    "        self.in_planes = 32 \n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # CHANGE: We only keep 3 layers. \n",
    "        # Layer 1: 32 channels\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        # Layer 2: 64 channels\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        # Layer 3: 128 channels\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        \n",
    "        # CHANGE: Removed layer4 (256/512 channels) because it consumes too many parameters\n",
    "        \n",
    "        # CHANGE: Linear layer input is now 128 (output of layer3)\n",
    "        self.linear = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        # out = self.layer4(out) # REMOVED\n",
    "        \n",
    "        # CHANGE: Global Average Pooling (Adaptive ensures 1x1 output regardless of input size)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class CorrectBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # 1. Preserve the input data to serve as the residual (shortcut) connection.\n",
    "        # It automatically adjusts dimensions if they mismatch; otherwise, it remains an identity mapping (passing x directly).\n",
    "        residual = self.shortcut(x)\n",
    "\n",
    "        # 2. Main Path: Execute standard convolution operations.\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # 3. Core Step: Add the output from the main path to the residual from the shortcut connection.\n",
    "        out += residual \n",
    "\n",
    "        # 4. Apply the final ReLU activation function.\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  708228\n"
     ]
    }
   ],
   "source": [
    "# Re-initialize the model to start fresh\n",
    "model = TinyResNet(block=CorrectBlock, num_blocks=[2,2,2]).to(DEVICE)\n",
    "\n",
    "# Define the optimizer (SGD with momentum is standard for ResNets)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Define the Scheduler\n",
    "# This will multiply the LR by 0.1 at epoch 15 and again at epoch 25\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "#     optimizer, \n",
    "#     milestones=[30, 50], \n",
    "#     gamma=0.1\n",
    "# )\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=60)\n",
    "\n",
    "print(\"Model parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss=4.386505866537289\n",
      "Epoch 1: Loss=4.122163393059555\n",
      "Epoch 2: Loss=3.9369625655972227\n",
      "Epoch 3: Loss=3.7838287499486185\n",
      "Epoch 4: Loss=3.6249174487834073\n",
      "Epoch 5: Loss=3.452512960044705\n",
      "Epoch 6: Loss=3.3506851196289062\n",
      "Epoch 7: Loss=3.1916465856591048\n",
      "Epoch 8: Loss=3.0702027155428517\n",
      "Epoch 9: Loss=2.990234355537259\n",
      "Epoch 10: Loss=2.9006363810325158\n",
      "Epoch 11: Loss=2.824263796514394\n",
      "Epoch 12: Loss=2.7646097601676476\n",
      "Epoch 13: Loss=2.7089332853044783\n",
      "Epoch 14: Loss=2.6535578114645824\n",
      "Epoch 15: Loss=2.6094708150746873\n",
      "Epoch 16: Loss=2.5650940573945338\n",
      "Epoch 17: Loss=2.515693051474435\n",
      "Epoch 18: Loss=2.4844201681565266\n",
      "Epoch 19: Loss=2.4435496719516054\n",
      "Epoch 20: Loss=2.41123873360303\n",
      "Epoch 21: Loss=2.3754667116671193\n",
      "Epoch 22: Loss=2.3455662046160017\n",
      "Epoch 23: Loss=2.3335095084443385\n",
      "Epoch 24: Loss=2.300577484831518\n",
      "Epoch 25: Loss=2.2661081771461333\n",
      "Epoch 26: Loss=2.24845721770306\n",
      "Epoch 27: Loss=2.2317495297412484\n",
      "Epoch 28: Loss=2.2023681913103377\n",
      "Epoch 29: Loss=2.175903860403567\n",
      "Epoch 30: Loss=2.1639444098180656\n",
      "Epoch 31: Loss=2.143165296437789\n",
      "Epoch 32: Loss=2.123620943147309\n",
      "Epoch 33: Loss=2.112384353365217\n",
      "Epoch 34: Loss=2.089726920030555\n",
      "Epoch 35: Loss=2.0656765772371877\n",
      "Epoch 36: Loss=2.05655300617218\n",
      "Epoch 37: Loss=2.0414687589723237\n",
      "Epoch 38: Loss=2.0312551114023947\n",
      "Epoch 39: Loss=2.008619469039294\n",
      "Epoch 40: Loss=1.9946520401507009\n",
      "Epoch 41: Loss=1.973636666122748\n",
      "Epoch 42: Loss=1.9665206622104257\n",
      "Epoch 43: Loss=1.95352861589315\n",
      "Epoch 44: Loss=1.935759773059767\n",
      "Epoch 45: Loss=1.9287833583598235\n",
      "Epoch 46: Loss=1.9157509171232885\n",
      "Epoch 47: Loss=1.894230494693834\n",
      "Epoch 48: Loss=1.8900793498876143\n",
      "Epoch 49: Loss=1.8867370766036364\n",
      "Epoch 50: Loss=1.8723567918855317\n",
      "Epoch 51: Loss=1.8687603230379066\n",
      "Epoch 52: Loss=1.86416203148511\n",
      "Epoch 53: Loss=1.855107764808499\n",
      "Epoch 54: Loss=1.8536798151171938\n",
      "Epoch 55: Loss=1.8464506913204581\n",
      "Epoch 56: Loss=1.8458868192166697\n",
      "Epoch 57: Loss=1.838346768398674\n",
      "Epoch 58: Loss=1.8374870310024338\n",
      "Epoch 59: Loss=1.8367603433375457\n"
     ]
    }
   ],
   "source": [
    "# Train using the fit_scheduler function\n",
    "# Make sure to use fit_scheduler, not just fit, so the LR updates happen!\n",
    "train_losses = fit_scheduler(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    epochs=60, # again, 60 epochs due to data augmentation\n",
    "    device=DEVICE,\n",
    "    scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 1.1840, Accuracy: 6844/10000 (68%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.1840345947265625, tensor(68.4400, device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss\n",
    "plot_loss(train_losses)\n",
    "\n",
    "# Evaluate on the test set\n",
    "predict(\n",
    "    model,\n",
    "    test_dataloader=test_dataloader,\n",
    "    device=DEVICE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
