{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: optimization of a CNN model\n",
    "The task of this homework is to optimize a CNN model for the CIFAR-100. You are free to define the architecture of the model, and the training procedure. The only contraints are:\n",
    "- It must be a `torch.nn.Module` object\n",
    "- The number of trained parameters must be less than 1 million\n",
    "- The test dataset must not be used for any step of training.\n",
    "- The final training notebook should run on Google Colab within a maximum 1 hour approximately.\n",
    "- Do not modify the random seed, as they are needed for reproducibility purpose.\n",
    "\n",
    "For the grading, you must use the `evaluate` function defined below. It takes a model as input, and returns the test accuracy as output.\n",
    "\n",
    "As a guideline, you are expected to **discuss** and motivate your choices regarding:\n",
    "- Model architecture\n",
    "- Hyperparameters (learning rate, batch size, etc)\n",
    "- Regularization methods\n",
    "- Optimizer\n",
    "- Validation scheme\n",
    "\n",
    "A code without any explanation of the choices will not be accepted. Test accuracy is not the only measure of success for this homework.\n",
    "\n",
    "Remember that most of the train process is randomized, store your model's weights after training and load it before the evaluation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Fix all random seeds\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# For full determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Import the best device available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# load the data\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "def evaluate(model):\n",
    "    params_count = sum(p.numel() for p in model.parameters())\n",
    "    print('The model has {} parameters'.format(params_count))\n",
    "\n",
    "    if params_count > int(1e6):\n",
    "        print('The model has too many parameters! Not allowed to evaluate.')\n",
    "        return\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "    # print in bold red in a notebook\n",
    "    print('\\033[1m\\033[91mAccuracy on the test set: {}%\\033[0m'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of a simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  556708\n"
     ]
    }
   ],
   "source": [
    "class TinyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = torch.nn.Linear(8*8*64, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.conv1(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = torch.nn.functional.relu(self.conv2(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 8*8*64)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "print(\"Model parameters: \", sum(p.numel() for p in TinyNet().parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of basic training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4.6139\n",
      "Epoch [2/10], Loss: 4.5809\n",
      "Epoch [3/10], Loss: 4.5755\n",
      "Epoch [4/10], Loss: 4.5898\n",
      "Epoch [5/10], Loss: 4.5963\n",
      "Epoch [6/10], Loss: 4.5981\n",
      "Epoch [7/10], Loss: 4.6149\n",
      "Epoch [8/10], Loss: 4.5327\n",
      "Epoch [9/10], Loss: 4.5011\n",
      "Epoch [10/10], Loss: 4.3966\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = TinyNet()\n",
    "model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 556708 parameters\n",
      "\u001b[1m\u001b[91mAccuracy on the test set: 3.4%\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# save the model on a file\n",
    "torch.save(model.state_dict(), 'tiny_net.pt')\n",
    "\n",
    "loaded_model = TinyNet()\n",
    "loaded_model.load_state_dict(torch.load('tiny_net.pt', weights_only=True))\n",
    "evaluate(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My TinyResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Preventing potential library conflicts on my Windows machine---#\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# Define functions needed, copy from training_utils.py of course material TP10\n",
    "# import everything else that we need\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function implements the core components of any Neural Network training regiment.\n",
    "    In our stochastic setting our code follows a very specific \"path\". First, we load the batch\n",
    "    a single batch and zero the optimizer. Then we perform the forward pass, compute the gradients and perform the backward pass. And ...repeat!\n",
    "    \"\"\"\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        # move data and target to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # do the forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "\n",
    "        # compute the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # perform the gradient step\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(train_dataloader)\n",
    "\n",
    "\n",
    "def fit(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    "):\n",
    "    \"\"\"\n",
    "    the fit method simply calls the train_epoch() method for a\n",
    "    specified number of epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    # keep track of the losses in order to visualize them later\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = train_epoch(\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "        )\n",
    "        print(f\"Epoch {epoch}: Loss={running_loss}\")\n",
    "        losses.append(running_loss)\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "def predict(\n",
    "    model: nn.Module, test_dataloader: DataLoader, device: torch.device, verbose=True\n",
    "):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, target, reduction=\"sum\")\n",
    "            test_loss += loss.item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    accuracy = 100.0 * correct / len(test_dataloader.dataset)\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Test set: Avg. loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_dataloader.dataset)} ({accuracy:.0f}%)\"\n",
    "        )\n",
    "\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "def visualize_images(dataloader):\n",
    "    images = next(iter(dataloader))[0][:10]\n",
    "    grid = torchvision.utils.make_grid(images, nrow=5, padding=10)\n",
    "\n",
    "    def show(img):\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation=\"nearest\")\n",
    "\n",
    "    show(grid)\n",
    "\n",
    "\n",
    "def plot_loss(losses, ylim=None):\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.ylim(ylim)\n",
    "    plt.title(\"Loss progression across epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# define the hyperparameters\n",
    "BATCH_SIZE = 1024\n",
    "TEST_BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# find out which device is available\n",
    "DEVICE = None\n",
    "if torch.cuda.is_available():\n",
    "    # Requires NVIDIA GPU with CUDA installed\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    # Requires Apple computer with M1 or later chip\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    # Not recommended, because it's slow. Move to Google Colab!\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Augmentation applied to train_dataset.transform\n"
     ]
    }
   ],
   "source": [
    "# first we load all the necessary libraries\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     torchvision.transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# # load the train dataset\n",
    "# train_dataset = torchvision.datasets.CIFAR10(\n",
    "#     root='./data/',\n",
    "#     train=True,\n",
    "#     download=True,\n",
    "#     transform=transform)\n",
    "\n",
    "# # load the test dataset\n",
    "# test_dataset = torchvision.datasets.CIFAR10(\n",
    "#     root='./data/',\n",
    "#     train=False,\n",
    "#     download=True,\n",
    "#     transform=transform)\n",
    "\n",
    "\n",
    "# Data Argumentation\n",
    "# CIFAR-10 Mean and Std\n",
    "# These values are commonly used for CIFAR-10 normalization\n",
    "stats = ((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "\n",
    "# 1. 定义增强的 Transform (仅用于训练集)\n",
    "# 包括：随机裁剪、随机水平翻转、转Tensor、归一化\n",
    "train_transform_augmented = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),       # 四周填充4像素后随机裁剪\n",
    "    transforms.RandomHorizontalFlip(),          # 50%概率水平翻转\n",
    "    transforms.ToTensor(),                      # 必须有，将图片转为Tensor\n",
    "    # CIFAR-10 的标准均值和方差归一化\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "# 2. 定义测试集的 Transform (通常不做增强，但建议做归一化以匹配训练集)\n",
    "test_transform_normalized = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "# 3. 【关键步骤】直接覆盖原有 dataset 对象的 transform 属性\n",
    "# 这样 train_dataloader 在取数据时就会自动应用新的增强策略\n",
    "train_dataset.transform = train_transform_augmented\n",
    "test_dataset.transform = test_transform_normalized\n",
    "\n",
    "print(\"Data Augmentation applied to train_dataset.transform\")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2)\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_scheduler(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    "    scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None # Scheduler\n",
    "):\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = train_epoch(\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "        )\n",
    "        print(f\"Epoch {epoch}: Loss={running_loss}\")\n",
    "        losses.append(running_loss)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step() # 每调用一次 step()，调度器会根据预设策略更新优化器的学习率\n",
    "            # 如果你用的是 ReduceLROnPlateau，它需要传入一个指标（如验证损失），所以调用方式是 scheduler.step(metric)，而不是空参数\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyTinyResNet(nn.Module):\n",
    "#     def __init__(self, block, num_blocks, num_classes=10): # e.g., num_blocks=[2,2,2,2] for ResNet18, block = NonResidualBlock, can be other blocks too\n",
    "#         super().__init__()\n",
    "#         self.in_planes = 64\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(64)\n",
    "#         self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "#         self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "#         self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "#         self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "#     def _make_layer(self, block, planes, num_blocks, stride):\n",
    "#         strides = [stride] + [1]*(num_blocks-1)\n",
    "#         layers = []\n",
    "#         for stride in strides:\n",
    "#             layers.append(block(self.in_planes, planes, stride)) #self\n",
    "#             self.in_planes = planes\n",
    "#         return nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = F.relu(self.bn1(self.conv1(x)))\n",
    "#         out = self.layer1(out)\n",
    "#         out = self.layer2(out)\n",
    "#         out = self.layer3(out)\n",
    "#         out = self.layer4(out)\n",
    "#         out = F.avg_pool2d(out, 4)\n",
    "#         out = out.view(out.size(0), -1)\n",
    "#         out = self.linear(out)\n",
    "#         return out\n",
    "\n",
    "class TinyResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=100): # CHANGE: Default classes to 100\n",
    "        super().__init__()\n",
    "        # CHANGE: Reduce initial channels from 64 to 32 to save parameters\n",
    "        self.in_planes = 32 \n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # CHANGE: We only keep 3 layers. \n",
    "        # Layer 1: 32 channels\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        # Layer 2: 64 channels\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        # Layer 3: 128 channels\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        \n",
    "        # CHANGE: Removed layer4 (256/512 channels) because it consumes too many parameters\n",
    "        \n",
    "        # CHANGE: Linear layer input is now 128 (output of layer3)\n",
    "        self.linear = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        # out = self.layer4(out) # REMOVED\n",
    "        \n",
    "        # CHANGE: Global Average Pooling (Adaptive ensures 1x1 output regardless of input size)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class CorrectBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # 1. 保存输入数据，准备作为残差（捷径）\n",
    "        # 注意：这里的 shortcut 已经在 __init__ 里定义好了，\n",
    "        # 如果维度不匹配它会自动调整，如果匹配它就是空的（相当于直接传 x）\n",
    "        residual = self.shortcut(x)\n",
    "\n",
    "        # 2. 主路径（Main Path）：正常的卷积操作\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # 3. 核心步骤：将主路径的结果与捷径的结果相加\n",
    "        out += residual \n",
    "\n",
    "        # 4. 最后再过一次 ReLU 激活函数\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  708228\n"
     ]
    }
   ],
   "source": [
    "# Re-initialize the model to start fresh\n",
    "model = TinyResNet(block=CorrectBlock, num_blocks=[2,2,2]).to(DEVICE)\n",
    "\n",
    "# Define the optimizer (SGD with momentum is standard for ResNets)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Define the Scheduler\n",
    "# This will multiply the LR by 0.1 at epoch 15 and again at epoch 25\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, \n",
    "    milestones=[30, 50], \n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "print(\"Model parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss=4.101642000431917\n",
      "Epoch 1: Loss=3.6081961612312163\n",
      "Epoch 2: Loss=3.2996959442995033\n",
      "Epoch 3: Loss=2.9700450167364005\n",
      "Epoch 4: Loss=2.7092232850133158\n",
      "Epoch 5: Loss=2.505048532875217\n",
      "Epoch 6: Loss=2.312738832162351\n",
      "Epoch 7: Loss=2.1728013097023475\n",
      "Epoch 8: Loss=2.0190120570513668\n",
      "Epoch 9: Loss=1.9226996047156197\n",
      "Epoch 10: Loss=1.8219304498361082\n",
      "Epoch 11: Loss=1.7214567563971694\n",
      "Epoch 12: Loss=1.649451165783162\n",
      "Epoch 13: Loss=1.5718754238011885\n",
      "Epoch 14: Loss=1.5051930826537463\n",
      "Epoch 15: Loss=1.4667638321312106\n",
      "Epoch 16: Loss=1.3968561912069515\n",
      "Epoch 17: Loss=1.3405627328522352\n",
      "Epoch 18: Loss=1.3003117478623683\n",
      "Epoch 19: Loss=1.2774960970392033\n",
      "Epoch 20: Loss=1.2347517743402598\n",
      "Epoch 21: Loss=1.1901600068929243\n",
      "Epoch 22: Loss=1.153749860062891\n",
      "Epoch 23: Loss=1.1243531290365725\n",
      "Epoch 24: Loss=1.1026294085444237\n",
      "Epoch 25: Loss=1.0754489679725803\n",
      "Epoch 26: Loss=1.052064095224653\n",
      "Epoch 27: Loss=1.0250885827200753\n",
      "Epoch 28: Loss=1.0131443203711996\n",
      "Epoch 29: Loss=0.9848325033577121\n",
      "Epoch 30: Loss=0.8049250451885924\n",
      "Epoch 31: Loss=0.724012455161737\n",
      "Epoch 32: Loss=0.7014236875942775\n",
      "Epoch 33: Loss=0.6888401046091196\n",
      "Epoch 34: Loss=0.6766181077275958\n",
      "Epoch 35: Loss=0.6642175243825329\n",
      "Epoch 36: Loss=0.6572422008125149\n",
      "Epoch 37: Loss=0.6485619836924027\n",
      "Epoch 38: Loss=0.6423408693196823\n",
      "Epoch 39: Loss=0.6292139328255946\n",
      "Epoch 40: Loss=0.6260066993382513\n",
      "Epoch 41: Loss=0.6139688905404539\n",
      "Epoch 42: Loss=0.6098490807474876\n",
      "Epoch 43: Loss=0.6057268636567252\n",
      "Epoch 44: Loss=0.5978848265141857\n",
      "Epoch 45: Loss=0.5907527147507181\n",
      "Epoch 46: Loss=0.5823115682115361\n",
      "Epoch 47: Loss=0.5786975439713926\n",
      "Epoch 48: Loss=0.5735867935784009\n",
      "Epoch 49: Loss=0.565080847667188\n",
      "Epoch 50: Loss=0.5418771079608372\n",
      "Epoch 51: Loss=0.535515563220394\n",
      "Epoch 52: Loss=0.5349636807733652\n",
      "Epoch 53: Loss=0.5327781706440206\n",
      "Epoch 54: Loss=0.5302062040689041\n",
      "Epoch 55: Loss=0.5271864253647474\n",
      "Epoch 56: Loss=0.5272930465182479\n",
      "Epoch 57: Loss=0.5274267774455401\n",
      "Epoch 58: Loss=0.5268248021602631\n",
      "Epoch 59: Loss=0.5284703203610012\n",
      "Test set: Avg. loss: 1.1856, Accuracy: 6756/10000 (68%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.18557958984375, tensor(67.5600, device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train using the fit_scheduler function\n",
    "# Make sure to use fit_scheduler, not just fit, so the LR updates happen!\n",
    "train_losses = fit_scheduler(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    epochs=60, # again, 60 epochs due to data augmentation\n",
    "    device=DEVICE,\n",
    "    scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training loss\n",
    "plot_loss(train_losses)\n",
    "\n",
    "# Evaluate on the test set\n",
    "predict(\n",
    "    model,\n",
    "    test_dataloader=test_dataloader,\n",
    "    device=DEVICE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
